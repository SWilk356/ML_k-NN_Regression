{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw8.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 8: Nearest Neighbors Regression üèò"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Sarah Wilkinson\n",
    "\n",
    "Student ID: 486676\n",
    "\n",
    "Collaborators: Vinya Reddy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "In this homework, we will be exploring a more realistic application of similarity-based leanring. It might be helpful to review **Lab 8: Similarity-based Prediction with k-NN** first. Most of the things we ask you to do in this homework are explained in the lab. In general, you should feel free to import any package that we have previously used in class. Ensure that all plots have all of the necessary components that a plot should have (e.g. axes labels, a title, a legend).\n",
    "\n",
    "Furthermore, in addition to recording your collaborators on this homework, please also remember to cite/indicate all external sources used when finishing this assignment. This includes peers, TAs, and links to online sources. Note that these citations will not free you from your obligation to submit your _own_ code and write-ups, however, they will be taken into account during the grading and regrading process.\n",
    "\n",
    "### Submission instructions\n",
    "* Submit this python notebook including your answers in the code cells as homework submission.\n",
    "* **Feel free to add as many cells as you need to** ‚Äî just make sure you don't change what we gave you. \n",
    "* **Does it spark joy?** Note that you will be partially graded on the presentation (_cleanliness, clarity, comments_) of your notebook so make sure you [Marie Kondo](https://lifehacker.com/marie-kondo-is-not-a-verb-1833373654) your notebook before submitting it. Remember that part of data science is the effective presentation of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using `sklearn` for $k$-Nearest Neighbors\n",
    "\n",
    "In Lab 8, we got familiar with $k$-nearest neighbors ($k$-NN) by implementing the algorithm. If you are still not comfortable with how the algorithm works, then we suggest that you review your work from the lab. In this home work, we will proceed under the assumption that you are familiar with $k$-NN.\n",
    "\n",
    "In this section, we will explore how to use the [$k$-NN _regression_ model supplied by `sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor). You can find the [$k$-NN _classification_ model here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing the Data\n",
    "\n",
    "We'll need to start by getting some data ‚Äî what is data science without data? For this assignment, we will be revisiting another old friend: the Boston Housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X_all, y = boston.data, boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we're here, let's review what this dataset is about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 1.1\n",
    "\n",
    "**Write-up!** How many examples are in the dataset? How many features does it have? What are the features? What is the target variable that we would like to estimate/predict? What kind of machine learning problem is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 506 examples or data points in the data. This dataset has 14 features. These features include per capita crime rate by town, proportion of residential land zoned for lots over 25,000 sq.ft, proportion of non-retail business acres per town\n",
    ", Charles River dummy variable (= 1 if tract bounds river; 0 otherwise), nitric oxides concentration (parts per 10 million), average number of rooms per dwelling\n",
    ", proportion of owner-occupied units built prior to 1940, weighted distances to five Boston employment centres, index of accessibility to radial highways, full-value property-tax rate per $10,000, pupil-teacher ratio by town, 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town, % lower status of the population, Median value of owner-occupied homes in $1000's. The target variable is Median value of owner-occupied homes in $1000's.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Based on our discussions in `Lab4` and `hw4`, we will include all data points and all features but _1000(Bk - 0.63)^2_ where _Bk_ is the proportion of blacks by town encoded as `'B'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'B' feature\n",
    "features_to_use = boston.feature_names!='B'\n",
    "X = X_all[:, features_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data\n",
    "\n",
    "In the lab, we also looked at data scaling and transformations. Here we'll demonstrate how to use `sklearn` to help us with this.\n",
    "\n",
    "**Approach 1:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# new train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=8)\n",
    "\n",
    "# compute the mean and standard deviation on a training set \n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# apply the transforamtion to both the trainnig and the test set\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 2:** \n",
    "An alternative and much quicker way of scaling the the data is the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 1.2\n",
    "\n",
    "**Write-up** What types of scaling does `StandardScaler()` and `scale` perform? Which of the two procedures is a more appropriate preprocessing step for supervised machine learning and _why_? \n",
    "> **Hint:** Use the [`?` operator](https://ipython.readthedocs.io/en/stable/interactive/python-ipython-diff.html#accessing-help) to get more information about the two scaling methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler() removes the mean and scales the data to unit variance. Scale centers the data to the mean and component wise scales to unit variance. Unit variance means that the standard deviation of a sample as well as the variance will tend towards 1 as the sample size tends towards infinity. This is helpful because it means that our data will be within a similar range, which is necessary for models that use a distance measure to measure similarity, like the KNN model, to prevent one feature from overshadowing the others. We would want to use StandardScaler() for supervised machine learning because it allows us to apply the same transformation to another set, which we would need to do for the testing set in order to get valid output that we can use to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Looking Into the Model\n",
    "\n",
    "Now that we have some data to play with, let's try building a $k$-NN regression model. The model provided by `sklearn` shares a similar interface with the other models that we have looked at previously (especially $k$-means)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.3\n",
    "\n",
    "Use the [`?` operator](https://ipython.readthedocs.io/en/stable/interactive/python-ipython-diff.html#accessing-help) provided by IPython to explore `model` and it's interface.\n",
    "\n",
    "**Do this!** In the cell below, complete the following:\n",
    "1. create and fit a new `KNeighborsRegressor` model with 5 neighbors.\n",
    "2. make some predictions using the model on your testing data.\n",
    "3. evaluate the performance of the model by computing $R^2$ and storing it in `r_squared`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7051364300656733"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "r_squared = model.score(X_test, y_test)\n",
    "\n",
    "r_squared\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1c</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1c results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 1.4\n",
    "\n",
    "**Write-up!** What was the $R^2$ value for your k-NN model using five neighbors? What does $R^2$ tell you about a model? What does this particular score tell you about your k-NN model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**SOLUTION:**\n",
    "The R^2 value for my k-NN model using five neighbors was 0.7051364300656733. R^2 is used to tell how much of the variation in the dependent variable can be explained by the independent variable(s). This means that about 70% of the observed variation in this model can be explained by the model's inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "With that, let's move on to some more interesting things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choosing $k$ with Cross Validation\n",
    "\n",
    "In order to test whether the `k-NN` algorithm (or any other machine learning algorithm) performs how we want it to and accurately makes predictions, we must compare the known label of all datapoints to the predicted label of those same datapoints. So far we have seen this in the forms of model evaluation and validation in model selection. \n",
    "\n",
    "In model evaluation we partitioned our original dataset into two parts: a training set and a testing set. As we have seen earlier in the course, the testing set is a smaller percentage of the total dataset than the training set.\n",
    "\n",
    "Later on, in model selection, we explored why it was important to have yet another set of data partitioned out for usage as a validation set, which we could use to experiment with a model's hyperparameters (value that is used to control the learning process). The validation set allowed us to \"evaluate\" our model's performance with various settings of its parameters while maintaining a completely untouched dataset for out final evaluation.\n",
    "\n",
    "We can extend this idea once again to improve our estimates of model performance using **cross validation**.\n",
    "\n",
    "> **CAUTION:** It is a total coincidence that for cross-valiation the number of partitions, also called folds, are typically numbered with the variable _k_. \n",
    "\n",
    "> **This** k **as in \"k-fold cross-validataion\" has nothing to do with the** k **in k-NN!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `kFolds` method\n",
    "\n",
    "One version of cross validation partitions the dataset into `k` partitions, or folds. We use `k-1` folds to train the model and one fold (fold we left out) to test the model. We iterate this process `k` times, leaving out a different fold each time, so that we have an accuracy score for each one of the `k` different partitions. We can then take the average of all of these accuracies to calculate a more wholistic accuracy representation of the algorithm. In the example below, `k = 5`; there are 5 partitions. Each partition is used once as a test partition while the other 4 are used for training purposes. The idea for $k$-fold cross validation is based on the realization that we can get a better picture of our model's performance by feeding it different combinations of our data.\n",
    "\n",
    "![](utility/pics/kFold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [`KFold`üîó](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) function from `sklearn`to partition our dataset into `n_splits` partitions. While the `KFold` function does not split the dataset itself, it provides the **indices** on which to split the dataset.\n",
    "\n",
    "Below, we split an random array of length 10 into 5 folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [21 68 47 37 14 67 73 59 75 77]\n",
      "For iteration 0: Train indices: [0 1 4 5 6 7 8 9]. Test indices: [2 3]\n",
      "For iteration 1: Train indices: [0 2 3 4 5 7 8 9]. Test indices: [1 6]\n",
      "For iteration 2: Train indices: [1 2 3 4 5 6 8 9]. Test indices: [0 7]\n",
      "For iteration 3: Train indices: [0 1 2 3 5 6 7 9]. Test indices: [4 8]\n",
      "For iteration 4: Train indices: [0 1 2 3 4 6 7 8]. Test indices: [5 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "dummy = np.random.randint(10, 100, size = 10) # example data\n",
    "print(f'data: {dummy}')\n",
    "\n",
    "# initialize KFolds\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# iterating over k different splits of dummy\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(dummy)):\n",
    "    print(f'For iteration {fold}: Train indices: {train_idx}. Test indices: {test_idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how each testing datapoint appears once, ensuring that all datapoints have had a chance to be be tested against the model trained with the rest of the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1\n",
    "\n",
    "Now, let's use the `KFold` operation on the full Boston Housing dataset.\n",
    "\n",
    "**Do this!** Complete the `knn_kfolds` function so that it performs `n_folds`-fold cross validation on the dataset `X` and applies $k$-NN regression with k=`n_neighbors` nearest neighbors. The function should return the average $R^2$ value of the model across the folds as `avg_score`.\n",
    "\n",
    "* Make sure to **scale** your training and test sets appropriately (√† la the [Scaling Data](#Scaling-Data) section).\n",
    "* Ensure that you make and **fit a new model** for each fold.\n",
    "* Also, please make sure that you set `random_state` appropriately in your initialization of `KFold`.\n",
    "\n",
    ">**Hint**: Refer to the previous example of how to use `KFold` and your work in [Problem 1.2](#Problem-1.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def knn_kfolds(X, y, n_folds, n_neighbors, random_state=None):\n",
    "    r_sqrd = []\n",
    "    model2 = KFold(n_splits = n_folds, shuffle = True, random_state=random_state)\n",
    "    for train_in, test_in in model2.split(X):\n",
    "        X_train, X_test = X[train_in], X[test_in]\n",
    "        y_train, y_test = y[train_in], y[test_in]\n",
    "        \n",
    "        scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        model = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        r_sqrd.append(model.score(X_test_scaled, y_test))\n",
    "    \n",
    "    avg_score = sum(r_sqrd)/n_folds\n",
    "    \n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2a</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2a results: All test cases passed!"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7652077509624957"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_kfolds(X, y, 5, 3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing $k$\n",
    "\n",
    "We can use cross validation as a substitute for the model selection algorithm that we've used in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 2.2\n",
    "\n",
    "In this problem, we will use cross validation and our `knn_kfolds` function to help us pick the right $k$ to use for our Boston Housing predictions.\n",
    "\n",
    "**Do this!** In the following cell, use `knn_kfolds()` to preform 10-fold cross validation on `X` and `y` to evaluate the performance of $k$-NN on the Boston Housing dataset and provide a plot of the cross validation average $R^2$ values for neares neighbor values `k` from 1 to 20 (inclusive). Use a `random_state` of 12 for your analysis. Ensure that your plot has all of the appropriate components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "r_values = []\n",
    "\n",
    "for k in range(1, 21):\n",
    "    r_values.append(knn_kfolds(X, y, 10, k, random_state=12))\n",
    "\n",
    "plt.plot(range(1, 21), r_values)\n",
    "plt.title(\"KNN accuracy with k values from 1-20\")\n",
    "plt.xlabel(\"# of folds\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 2.3\n",
    "\n",
    "**Write-up!** Based on your plot from [Problem 2.2](#Problem-2.2), which $k$ value would you pick for your final model? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would choose 2 as the k value because that is when the model is most accurate, as seen in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 3. Model Comparison with Cross Validation\n",
    "\n",
    "As mentioned before, we can use cross validation to get a more thorough evaluation of model performance. Now, we will use CV for model comparison by substituting it in for the model selection process that we have used in above. Note that the approach below is actually not quite legal, since we already used all our data in kNN to select k in **Problem 2.2** and now we are using the _same_ data again to preform model comparison. \n",
    "\n",
    "In this section, we will compare our $k$-NN regression model with a linear regression model that we used back in `Lab4` when we last looked at the Boston Housing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.1\n",
    "\n",
    "**Do this!** In the following cell, report the cross validation score (average $R^2$) of a $k$-NN model with the $k$ you selected in [Problem 2.3](#Problem-2.3) on `X_scaled`. Use a `random_state` of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7995681654409791"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score = knn_kfolds(X, y, 10, 2, random_state=5)\n",
    "\n",
    "cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 3.2\n",
    "\n",
    "Now let's do 10-fold cross validation on a linear regression model on `X` without scaling.\n",
    "\n",
    "**Write-up** Why should shouldn't we use scaling here? What will happen if we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression doesn't require scaling because it doesn't do anything for a straight line. Scaling will only yield an equivalent solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Do this!** Perform 10-fold cross validation for linear regression on `X` and report the average $R^2$ value across all of the folds.\n",
    "\n",
    "* Ensure that you make and **fit a new model** for each fold.\n",
    "* Use the same random state as we used to evaluate k-NN, so that the cross-validation splits stay the **same**. \n",
    "\n",
    "> **Hint:** Refer to your work in [Problem 2.1](#Problem-2.1) and [Problem 3.1](#Problem-3.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7010882408167969"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "r_sqrd = []\n",
    "model3 = KFold(n_splits = 10, shuffle = True, random_state=10)\n",
    "for train_in, test_in in model3.split(X):\n",
    "    X_train, X_test = X[train_in], X[test_in]\n",
    "    y_train, y_test = y[train_in], y[test_in]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    r_sqrd.append(model.score(X_test, y_test))\n",
    "\n",
    "avg_score = sum(r_sqrd)/10\n",
    "\n",
    "avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 3.3\n",
    "\n",
    "**Write-up!** What were the $R^2$ values for each of the models? Which model would you prefer? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R2 value for the Linear Regression model is 0.7010882408167972, while the R2 value for the KNeighborsRegressor model is 0.7652077509624957. I would choose the KNeighborsRegressor model because it has a higher accuracy on average. Note that we would not want too high of an accuracy because want to avoid overfitting, but 76.5% is not so high that we need to worry about that yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 3.4\n",
    "\n",
    "**Write-up!** What are your next steps as a data scientist now that you have decided which model to use? Describe two things (related to the DS workflow of this project). Did you notice any thing in our workflow above that was"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have completed our model selection portion of the DS workflow, we should move on to optimizing the model. Once the model is optimized, we should run it on a new dataset, the testing set, to see if it really is accurate (though we unfortunately already used our testing data as our validation set, but suppose that we have another dataset to test with). If we find that it is not accurate, it's back to validating and tweaking, and we may need more data for that, so we may also need to repeat the data collection and cleaning/scaling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Write-up!** Did you notice any thing in our workflow above that was not quite right? If so share your critical review with your boss (well for now, with us). Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cleaned and scaled our data, and then we used the data on two different models, a KNN model and a linear regression model. Using the models' R2 statistic, we determined that the KNN model was a better choice for the data. When we were setting up our data for use, however, we only created a training and a testing set. We used the training set to train the models, and we used the testing set to evaluate their accuracies. We have no more data for further testing the model now, meaning that we cannot confirm how well the model performs. We will have to tell our boss that we do not know how much more accurate the model can be without more data, which they may not like because they'll have to go get more data, and that's pretty expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1c results: All test cases passed!\n",
       "\n",
       "q2a results: All test cases passed!\n",
       "\n",
       "q3a results: All test cases passed!"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <p>Your submission has been exported. Click <a href=\"hw8_2021_11_23T00_06_43_217161.zip\" download=\"hw8_2021_11_23T00_06_43_217161.zip\" target=\"_blank\">here</a>\n",
       "            to download the zip file.</p>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "otter": {
   "tests": {
    "q1c": {
     "name": "q1c",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(r_squared, 0.70514, rtol=1e-4) == True\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isscalar(knn_kfolds(X, y, 5, 3, random_state=10)) == True\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> avg_score = knn_kfolds(X, y, 5, 3, random_state=10)\n>>> 0 <= avg_score and avg_score <= 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
